
---
output:
  md_document:
    variant: markdown_github
---

```{r, echo = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "##",
  fig.path = "README-")
```

##corpuslingr: 

Some r functions for quick web scraping and corpus seach of complex grammtical constructions. Works in conjunction with `spacyr` package. 
```{r message=FALSE, warning=FALSE, paged.print=FALSE}
library(tidyverse)
devtools::install_github("jaytimm/corpuslingr")
#devtools::install_github("jaytimm/corpusdatr")
library(corpuslingr)
library(corpusdatr)
library(knitr)
library(data.table)
library(cleanNLP)

library(stringi)
```

##Web scraping functions
###GetGoogleNewsMeta()
```{r}
#dailyMeta <- corpuslingr::GetGoogleNewsMeta (search="New Mexico", n=5)
dailyMeta <- corpuslingr::GetGoogleNewsMeta (search="New Mexico",n=15)

head(dailyMeta['titles'])
```

We need to sort out meta with sites that are actually scraped.
Also, re-try "article" verion of boilerpipeR.

###GetWebTexts()
```{r}
txts <- dailyMeta$links  %>% 
  corpuslingr::GetWebTexts() %>% ##'You don't have permission ...'-business
  stringi::stri_enc_toutf8()
  
substr(txts[1:5],1, 50)
```

```{r}
nmTIF <- unlist(txts) %>%
  melt() %>%
  mutate(value=as.character(value),doc_id=row_number())%>%
  bind_cols(dailyMeta) %>%
  rename(txt = value) #%>%
  #mutate(txt=corpuslingr::PrepText(txt)) #PrepText. 

#This doesn't work -- returns list.
```


ModifyAnnotation() needs to be modified.  Will not work on non-spacyr annotations.  Need something akin to 'tuple parameters'


##Corpus preparation
###PrepAnnotation()
```{r eval=FALSE}
cleanNLP::cnlp_init_udpipe(model_name="english",feature_flag = FALSE, parser = "none") 

annotations <- cleanNLP::cnlp_annotate(nmTIF$txt, as_strings = TRUE) %>%
  Filter(length,.)
```


###GetDocDesc() 
```{r}
head(GetDocDesc(gnews))
```


##Search function and aggregate functions.
###GetContexts()
```{r}
search1 <- "<_Vx> <_IN>"

found <- corpuslingr::GetContexts(search=search1,corp=gnews,LW=5, RW = 5)
```


###GetSearchFreqs()
```{r}
corpuslingr::GetSearchFreqs(found)[[1]]
```

###GetKWIC()
```{r}
search2 <- "<_Jx> <and!> <_Jx>"

corpuslingr::GetContexts(search=search2,corp=gnews,LW=5, RW = 5)%>%
  corpuslingr::GetKWIC()%>%
  data.frame()%>%
  select(doc_id,cont)%>%
  mutate(cont=gsub("<mark>|</mark>","||",cont))%>%
  knitr::kable("markdown")
```

###GetBOW()
Vector space model, or word embedding
```{r}
search3 <- "<Trump!>"

corpuslingr::GetContexts(search=search3,corp=gnews,LW=15, RW = 15)%>%
  corpuslingr::GetBOW(contentOnly=TRUE)%>%
  data.frame()%>%
  slice(1:10)%>%
  ggplot(aes(x=reorder(lemma,n), y=n)) + 
    geom_bar(stat="identity", width=.5, fill="tomato3") +  
    coord_flip()+
    theme_bw()

##How would we get Noun Phrases from a BOW?
```



##Multi-term search

```{r}
#multi-search <- c("")
```


##Corpus workflow
```{r eval=FALSE, message=FALSE, warning=FALSE}
search4 <- "<_xNP> (<wish&> |<hope&> |<believe&> )"

dailyMeta$links  %>% 
  corpuslingr::GetWebTexts()%>%
  lapply(spacyr::spacy_parse,tag=TRUE)%>%
  corpuslingr::PrepAnnotation()%>%
  corpuslingr::GetContexts(search=search4,corp=.,LW=10, RW = 10)%>%
  corpuslingr::GetSearchFreqs(found)[[1]]
```



